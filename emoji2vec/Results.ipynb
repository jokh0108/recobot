{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kakao/.pyenv/versions/3.5.4/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "import sklearn.manifold as man\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "from model import Emoji2Vec, ModelParams\n",
    "from phrase2vec import Phrase2Vec\n",
    "from utils import build_kb, get_examples_from_kb, generate_embeddings, get_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializations\n",
    "This step takes a while to execute, wait for 'DONE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./results/unicode/k-300_pos-4_rat-1_ep-120_dr-0/emoji2vec.bin\n"
     ]
    }
   ],
   "source": [
    "word2vec_path = './data/word2vec/GoogleNews-vectors-negative300.bin'\n",
    "mapping_path = 'emoji_mapping.p'\n",
    "data_folder = './data/training/'\n",
    "embeddings_file = 'generated_embeddings.p'\n",
    "\n",
    "in_dim = 300   # Length of word2vec vectors\n",
    "out_dim = 300  # Desired dimension of output vectors\n",
    "pos_ex = 4\n",
    "neg_ratio = 1\n",
    "max_epochs = 40\n",
    "dropout = 0.0\n",
    "\n",
    "params = ModelParams(in_dim=in_dim, out_dim=out_dim, pos_ex=pos_ex, max_epochs=max_epochs,\n",
    "                    neg_ratio=neg_ratio, learning_rate=0.001, dropout=dropout, class_threshold=0.5)\n",
    "\n",
    "\n",
    "ckpt_path = params.model_folder('unicode') + '/model.ckpt'\n",
    "e2v_path = params.model_folder('unicode') + '/emoji2vec.bin'\n",
    "print(e2v_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading training data from: ./data/training/\n"
     ]
    }
   ],
   "source": [
    "print('reading training data from: ' + data_folder)\n",
    "train_kb, ind2phr, ind2emoj = build_kb(data_folder)\n",
    "\n",
    "pk.dump(ind2emoj, open(mapping_path, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read or Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading embeddings...\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "embeddings_array = generate_embeddings(ind2phr=ind2phr, kb=train_kb, embeddings_file=embeddings_file,\n",
    "                                             word2vec_file=word2vec_path)\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize models and mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing: reading embedding data from: ./data/word2vec/GoogleNews-vectors-negative300.bin\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './results/unicode/k-300_pos-4_rat-1_ep-120_dr-0/emoji2vec.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-95b61a82b7c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Initializing: reading embedding data from: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mword2vec_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# get the vector for a phrase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mphraseVecModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPhrase2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_word2vec_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2vec_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me2v_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DONE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/emoji2vec/phrase2vec.py\u001b[0m in \u001b[0;36mfrom_word2vec_paths\u001b[0;34m(cls, dim, w2v_path, e2v_path)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mw2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0me2v_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0me2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me2v_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0me2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.4/lib/python3.5/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading projection weights from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# throws for invalid file format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.4/lib/python3.5/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36msmart_open\u001b[0;34m(uri, mode, **kw)\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mtransport_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_ext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_extension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransport_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransport_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mscrubbed_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.4/lib/python3.5/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     )\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.4/lib/python3.5/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, ignore_ext, buffering, encoding, errors)\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './results/unicode/k-300_pos-4_rat-1_ep-120_dr-0/emoji2vec.bin'"
     ]
    }
   ],
   "source": [
    "print('Initializing: reading embedding data from: ' + word2vec_path)\n",
    "# get the vector for a phrase\n",
    "phraseVecModel = Phrase2Vec.from_word2vec_paths(params.in_dim, word2vec_path, e2v_path)\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops.reset_default_graph()\n",
    "\n",
    "# mapping from id to emoji\n",
    "mapping = pk.load(open(mapping_path, 'rb'))\n",
    "# mapping from emoji to id\n",
    "inv_map = {v: k for k, v in mapping.items()}\n",
    "\n",
    "# tensorflow model\n",
    "model = Emoji2Vec(params, len(mapping), embeddings_array=embeddings_array)\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize tensorflow session\n",
    "session = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(session, ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Measures\n",
    "Check the accuracy, f1 score, auc, and the auc graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measures(example_type):\n",
    "    train_kb, ind2phr, ind2emoj = build_kb(data_folder)\n",
    "    ex_set = get_examples_from_kb(kb=train_kb, example_type=example_type)\n",
    "\n",
    "    # evaluate the dev. accuracy using this as the threshold\n",
    "    thresh = 0.5\n",
    "\n",
    "    acc = model.accuracy(session=session, dset=ex_set, threshold=thresh)\n",
    "    f1 = model.f1_score(session=session, dset=ex_set)\n",
    "    print(str.format('Accuracy at thresh={}: {}', thresh, f1))\n",
    "    print(str.format('F1 score: {}', f1))\n",
    "    \n",
    "    try:\n",
    "        auc = model.auc(session=session, dset=ex_set)\n",
    "\n",
    "\n",
    "        print(str.format('AUC score: {}', auc))\n",
    "\n",
    "        fpr, tpr, thresholds = model.roc_vals(session=session, dset=ex_set)\n",
    "\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.plot(fpr, tpr)\n",
    "        ax.set_title(\"ROC Curve for learned emoji\")\n",
    "        plt.xlabel(\"false positive rate\")\n",
    "        plt.ylabel(\"true positive rate\")\n",
    "\n",
    "        #\n",
    "        #for i , val in enumerate(thresholds):\n",
    "        #    if i % 10 == 0:\n",
    "        #        plt.annotate(val, (fpr[i], tpr[i]))\n",
    "\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "    except:\n",
    "        print('Can\\'t compute AUC or ROC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Train Set')\n",
    "measures('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dev Set')\n",
    "measures('dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test Set')\n",
    "measures('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESET THE GRAPH\n",
    "ops.reset_default_graph()\n",
    "model = Emoji2Vec(params, len(mapping), embeddings_array=None, use_embeddings=False)\n",
    "\n",
    "session = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(session, ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top Emoji Query\n",
    "Set `phr` as a phrase, and get the top `N` emojis correlating to that phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "phr = 'happy face'\n",
    "N = 5\n",
    "\n",
    "# get the vector representaiton\n",
    "vec = phraseVecModel[phr]\n",
    "\n",
    "# query the tensorflow model\n",
    "res = list()\n",
    "for colIx in range(0, len(mapping)):\n",
    "    predict = session.run(model.prob, feed_dict={\n",
    "        model.col: np.array([colIx]),\n",
    "        model.orig_vec: np.array([vec])\n",
    "    })\n",
    "    res.append(predict)\n",
    "\n",
    "# print the top N emoji\n",
    "for ind in sorted(range(len(res)), key=lambda i: res[i], reverse=True)[:N]:\n",
    "    print(mapping[ind], res[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(phraseVecModel.wordVecModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top Phrase Query\n",
    "Set `em` as an emoji, and get the top `N` phrases correlating to that emoji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "em = 'üëë'\n",
    "N = 10\n",
    "\n",
    "# get the relevant vectors from tensorflow\n",
    "emoji_vecs = session.run(model.V)\n",
    "vec = emoji_vecs[inv_map[em]]\n",
    "\n",
    "# print top N phrases\n",
    "for word, score in phraseVecModel.from_emoji([vec], top_n=N):\n",
    "    print(str.format(\"{}\\t{}\", word, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analogy Task\n",
    "Set `base` as a base emoji, `minus` as an emoji to subtract from the base, `plus` as an emoji to add, and get the top `N` correlating phrases and emojis relating to this analogy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_analogy_result(base, minus, plus):\n",
    "    emoji_vecs = session.run(model.V)\n",
    "    total = phraseVecModel[base] - phraseVecModel[minus] + phraseVecModel[plus]\n",
    "    \n",
    "    res = list()\n",
    "    for colIx in range(0, len(mapping)):\n",
    "        predict = session.run(model.prob, feed_dict={\n",
    "            model.col: np.array([colIx]),\n",
    "            model.orig_vec: np.array([total / np.linalg.norm(total)])\n",
    "        })\n",
    "        res.append(predict)\n",
    "        \n",
    "    ems = sorted(range(len(res)), key=lambda i: res[i], reverse=True)[:5]\n",
    "    print(str.format('{} - {} + {} = {}', base, minus, plus, [mapping[em] for em in ems]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_analogy_result('üëë', 'üöπ', 'üö∫')\n",
    "print_analogy_result('üíµ', 'üá∫üá∏', 'üá¨üáß')\n",
    "print_analogy_result('üíµ', 'üá∫üá∏', 'üá™üá∫')\n",
    "print_analogy_result('üë¶', 'üë®', 'üë©')\n",
    "print_analogy_result('üë™', 'üë¶', 'üëß')\n",
    "print_analogy_result('üï∂', '‚òÄÔ∏è', '‚õà')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "base = 'üëë'\n",
    "# base = 'üë®'\n",
    "minus = 'üöπ'\n",
    "plus = 'üö∫'\n",
    "N = 10\n",
    "\n",
    "# get the relevant vectors from tensorflow\n",
    "emoji_vecs = session.run(model.V)\n",
    "total = emoji_vecs[inv_map[base]] - emoji_vecs[inv_map[minus]] + emoji_vecs[inv_map[plus]]\n",
    "\n",
    "total = phraseVecModel[\"I think I should buy zero cola\"]\n",
    "\n",
    "# print the top N phrases\n",
    "print(str.format('Top {} matching phrases:', N))\n",
    "print()\n",
    "for word, score in phraseVecModel.from_emoji([total], top_n=N):\n",
    "    print(str.format(\"{}\\t{}\", word, score))\n",
    "    \n",
    "# query the tensorflow model\n",
    "res = list()\n",
    "for colIx in range(0, len(mapping)):\n",
    "    predict = session.run(model.prob, feed_dict={\n",
    "        model.col: np.array([colIx]),\n",
    "        model.orig_vec: np.array([total / np.linalg.norm(total)])\n",
    "    })\n",
    "    predict[0] = predict[0]**5\n",
    "    res.append(predict)\n",
    "\n",
    "# print the top N emoji\n",
    "print()\n",
    "print(str.format('Top {} matching emoji:', N))\n",
    "print()\n",
    "for ind in sorted(range(len(res)), key=lambda i: res[i], reverse=True)[:N]:\n",
    "    print(mapping[ind], res[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Visualize Emoji Vector Space\n",
    "2-D projection of the Emoji vector space, using t-SNE.\n",
    "\n",
    "Jupyter won't plot emoji. Use visualize.py to see a clearer picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = session.run(model.V)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "tsne = man.TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "trans = tsne.fit_transform(V)\n",
    "x, y = zip(*trans)\n",
    "plt.scatter(x, y)\n",
    "\n",
    "for i in range(len(trans)):\n",
    "    ax.annotate(mapping[i], xy=trans[i], textcoords='data')\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
